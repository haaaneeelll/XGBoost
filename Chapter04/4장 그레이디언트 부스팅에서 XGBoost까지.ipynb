{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d94bce",
   "metadata": {},
   "source": [
    "- XGBoost는 5장에서 설명할 몇 가지 확실한 장점이 있는 독특한 형태의 그레이디언트 부스팅 구현이다.\n",
    "- 일반적인 그레이디언트 부스팅에 비해 XGBoost의 장점을 이해하려면 먼저 기존 그레이디언트 부스팅의 작동 방식을 알아야 한다.\n",
    "- 기존 그레이디언트 부스팅의 구조와 매개변수는 XGBoost에서도 제공한다. 이 장에서 XGBoost의 핵심인 강력한 그레이디언트 부스팅에 대해 알아보겠다.\n",
    "- 기존 그레이디언트 부스팅의 구조와 매개변수는 XGBoost에서도 제공한다. 이 장에서 XGBoost의 핵심인 강력한 그레이디언트 부스팅 대해 알아보겠다.\n",
    "- 이장에서 그레이디언트 부스팅 모델을 만들고 이전 결과와 비교해보겠다.\n",
    "- 특히 **학습률** 매개변수에 초점을 맞추어 XGBoost와 같은 강력한 그레이디언트 부스팅 모델을 만들어보겠다.\n",
    "- 마지막으로 빠른 알고리즘이 필요한 외계 행성 데이터셋 문제를 다루어보겠다. 속도는 빅 데이터 세계에서 핵심적인 요구사항이며 XGBoost는 이를 만족했다.\n",
    "\n",
    "-----\n",
    "# 이 장 구성\n",
    "\n",
    "- 배깅에서 부스팅까지\n",
    "- 그레이디언트 부스팅 작동 방식\n",
    "- 그레이디언트 부스팅 매개변수 튜닝\n",
    "- 빅 데이터 다루기 - 그레이디언트 부스팅 vs XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94887552",
   "metadata": {},
   "source": [
    "# 4.1 배깅에서 부스팅까지\n",
    "- 3장에서 랜덤 포레스트 같은 앙상블 머신러닝 알고리즘이 많은 모델을 하나로 연결하여 더 나은 예측을 만드는 이유를 배웠다.\n",
    "- **랜덤 포레스트**는 (결정 트리에서) 부트스트랩 샘플을 사용하기 때문에 배깅 알고리즘으로 분류된다.\n",
    "----\n",
    "- 이와 달리 **부스팅은 개별 트리의 실수로부터 학습한다. 이전 트리의 오차를 기반으로 새로운 트리를 훈련하는 것이 기본적인 아이디어다.**\n",
    "- 부스팅에서 새로운 트리에 대한 **오차를 수정**하는 것은 배깅과 다른 접근 방법이다. 배깅 모델에서는 새로운 트리가 이전 트리에 주의를 기울이지 않다. 또한 **새로운 트리는 부트스트래핑을 사용해 처음부터 훈련되며 최종 모델은 모든 개별 트리의 결과를 합친다.하지만 부스팅에서는 개별 트리가 이전 트리를 기반으로 만들어진다.** 독립적으로 트리가 동작하지 않으며 **다른 트리 위에 만들어진다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcaba42",
   "metadata": {},
   "source": [
    "## 4.1.1 에이다부스트 소개\n",
    "- 에이다부스트는 인기 있는 초기 부스팅 모델 중 하나이다.\n",
    "- 에디아부스트에서는 새로운 트리가 이전 트리의 오차를 기반으로 가중치를 조정한다.\n",
    "- 오류 샘플의 가중치를 높여 잘못된 예측에 더 많은 주의를 기울인다.\n",
    "- 에이다부스트는 이렇게 실수에서 학습하기 때문에 약한학습기를 강력한 학습기로 만들 수 있다. \n",
    "- 약한 학습기는 우연보다 조금 나은 성능을 내는 머신러닝 모델을 말한다.\n",
    "- 강한 학습기는 많은 양의 데이터에서 학습하여 매우 잘 수행되는 모델이다.\n",
    "----\n",
    "\n",
    "- 약한 학습기를 강력한 학습기로 변환하는 것이 부스팅 알고리즘의 일반적인 아이디어이다.\n",
    "- 약한 학습기는 무작위 예측보다 조금 낫다. 하지만 약한 학습기로 시작하는 데는 목적이 있다.\n",
    "- **일반적으로 부스팅은 강력한 기반 모델을 만드는 것이 아니라 반복적으로 오류를 고치는 데 초점을 맞춘다.**\n",
    "- 기반 모델이 너무 강력하면 학습 과정이 제한되어 부스팅 모델의 전략을 약화시킨다.\n",
    "\n",
    "- 수백 번의 반복을 통해 약한 학습기가 강력한 학습기로 바뀐다. 즉, 작은 성능 개선을 오래 지속한다.\n",
    "- 사실 부스팅은 지난 수십년 동안 최적의 결과를 만드는 점에서 가장 뛰어난 머신러닝 전략 중 하나이다.\n",
    "---\n",
    "- 에이다부스트의 강력한 대안인 그레이디언트 부스팅으로 넘어가겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff0c0ec",
   "metadata": {},
   "source": [
    "# 4.1.2 그레이디언트 부스팅의 특징\n",
    "- 그레이디언트 부스팅은 에이다부스트와 다른 전략을 사용한다.\n",
    "- 그레이디언트 부스팅도 잘못된 예측을 기반으로 조정되지만 한 단계 더 나아간다.\n",
    "- **그레이디언트 부스팅은 이전 트리의 예측 오차를 기반으로 완전히 새로운 트리를 훈련한다.**\n",
    "- 즉, 그레이디언트 부스팅은 각 트리의 실수를 살펴보고 이런 실수에 대한 **완전한 새로운 트리를 만든다.**\n",
    "- 새로운 트리는 올바르게 예측된 값에는 영향을 받지 않는다.\n",
    "\n",
    "---\n",
    "- 오차에만 초점을 맞추는 머신러닝 알고리즘을 만들려면 정확한 최종 예측을 만들기 위해 오차를 계산하는 방법이 필요하다.\n",
    "- 이런 방법은 모델의 예측과 실제 값 사이의 차이인 잔차를 활용한다. 일방적인 방법은 다음과 같다.\n",
    "\n",
    "- 그레이디언트 부스팅은 각 트리 예측 값을 더해 모델 평가에 사용한다.\n",
    "- 이 아이디어는 그레이디언트 부스팅의 고급 버전인 XGBoost의 핵심이므로 트리의 예측을 계산하고 더하는 것을 이해하는 것이 중요하다. 그레이디언트 부스팅 모델을 직접 만들어보면 예측을 계산하고 더하는 과정을 잘 볼 수 있다.\n",
    "- 다음 절에서 직접 그레이디언트 부스팅 모델을 만들어보겠다. 먼저 그레이디언트 부스팅의 작동방식에 대해 배워보겠다.\n",
    "\n",
    "---\n",
    "요약하면 AdaBoost와 Gradient Boosting은 모두 약한 학습자를 강력한 학습자로 결합하는 부스팅 알고리즘이지만 샘플에 가중치를 부여하는 접근 방식과 훈련 중에 앙상블을 업데이트하는 방법이 다릅니다. 보다 유연하고 강력한 Gradient Boosting은 종종 선호되며 광범위한 작업에서 더 나은 성능을 제공하는 경향이 있습니다.\n",
    "\n",
    "AdaBoost와 달리 Gradient Boosting은 데이터 포인트 가중치에 중점을 두지 않습니다. 대신, 각각의 새로운 약한 학습자를 잔차(실제 목표 값과 기존 앙상블에 의한 예측 간의 차이)에 맞춥니다.\n",
    "각 약한 학습자는 이전의 약한 학습자가 만든 오류를 줄여서 모델을 개선하려고 합니다."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "77ff50d3",
   "metadata": {},
   "source": [
    "## 4.2. 그레이디언트 부스팅 작동 방식\n",
    "- 그레이디언트 부스팅의 작동 방식을 살펴보고 이전 트리의 오차에 새로운 트리를 훈련하는 식으로 그레이디언트 부스팅 모델을 직접 만들어보자.\n",
    "- 여기서 수학적인 핵심 요소는 **잔차**이다. \n",
    "\n",
    "## 4.2.1 잔차\n",
    "- 잔차는 타깃과 모델의 예측 사이의 차이다. \n",
    "- 통계학에서는 일반적으로 선형 회귀 모델이 데이터에 얼마나 잘 맞는지 평가하기 위해 잔차를 사용한다.\n",
    "\n",
    ">다음과 같은 예를 생각해보자.\n",
    "1. 자전거 대여\n",
    "a)예측: 759\n",
    "b)타깃: 799\n",
    "c)잔차: 799-759 = 40\n",
    "\n",
    "2. 소득\n",
    "a)예측: 100,000\n",
    "b)타깃: 88,000\n",
    "c)잔차\" 88,000 - 100,000 = -12,000\n",
    "\n",
    "여기서 보듯이 잔차는 모델 예측이 정답에서 얼마나 떨어져 있는지 알려주며 양수 또는 음수일 수 있다.\n",
    "\n",
    "#### 선형회귀의 잔차\n",
    "![image.png](attachment:image.png)\n",
    "- 선형 회귀의 목적은 잔차의 제곱을 최소화하는 것이다. \n",
    "- 그림에 나와 있듯이 잔차는 선형 회귀 직선이 데이터에 얼마나 잘 맞는지 보여준다.\n",
    "- 통계학에서 종종 데이터에 대한 통찰을 얻기 위해 잔차를 그래프로 시각화하여 선형 회귀 분석을 수행한다.\n",
    "\n",
    "그레이디언트 부스팅 알고리즘을 직접 구현해보기 위해 각 트리의 잔차를 계산하고 이 잔차에 새로운 모델을 훈련해보겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74b4805",
   "metadata": {},
   "source": [
    "## 4.2.2 그레이디언트 부스팅 모델 구축 방법 배우기\n",
    "- 그레이디언트 부스팅 모델을 직접 만들어보면 그레이디언트 부스팅의 작동방식을 잘 이해할 수 있다.\n",
    "- 모델을 만들기 전에 데이터를 준비하고 모델에 주입할 수 있도록 나누자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a481f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xgboost as xgb\n",
    "xgb.set_config(verbosity = 0)\n",
    "\n",
    "# verbosity=0: verbosity 매개변수는 XGBoost 훈련 프로세스 중에 인쇄되는 정보의 양을 제어하는데 사용됩니다.\n",
    "# 값 0은 추가 정보(오류 제외)가 인쇄되지 않음을 의미합니다.\n",
    "# 1 이상으로 설정하면 진행률 및 성능 메트릭을 포함하여 교육 프로세스에 대한 자세한 정보가 인쇄됩니다.\n",
    "# 상세도를 0으로 설정하면 추가 정보의 인쇄를 억제하여 오류 메시지를 제외하고는 아무 출력 없이 교육 프로세스를 자동으로 만듭니다.\n",
    "# 이는 특히 대규모 실험을 실행하거나 과도한 출력이 필요하지 않은 프로덕션 환경에서 출력을 복잡하게 만들지 않으려는 경우에 유용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d2e4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.226642</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.255046</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant  season   yr  mnth  holiday  weekday  workingday  weathersit  \\\n",
       "0          1     1.0  0.0   1.0      0.0      6.0         0.0           2   \n",
       "1          2     1.0  0.0   1.0      0.0      0.0         0.0           2   \n",
       "2          3     1.0  0.0   1.0      0.0      1.0         1.0           1   \n",
       "3          4     1.0  0.0   1.0      0.0      2.0         1.0           1   \n",
       "4          5     1.0  0.0   1.0      0.0      3.0         1.0           1   \n",
       "..       ...     ...  ...   ...      ...      ...         ...         ...   \n",
       "726      727     1.0  1.0  12.0      0.0      4.0         1.0           2   \n",
       "727      728     1.0  1.0  12.0      0.0      5.0         1.0           2   \n",
       "728      729     1.0  1.0  12.0      0.0      6.0         0.0           2   \n",
       "729      730     1.0  1.0  12.0      0.0      0.0         0.0           1   \n",
       "730      731     1.0  1.0  12.0      0.0      1.0         0.0           2   \n",
       "\n",
       "         temp     atemp       hum  windspeed   cnt  \n",
       "0    0.344167  0.363625  0.805833   0.160446   985  \n",
       "1    0.363478  0.353739  0.696087   0.248539   801  \n",
       "2    0.196364  0.189405  0.437273   0.248309  1349  \n",
       "3    0.200000  0.212122  0.590435   0.160296  1562  \n",
       "4    0.226957  0.229270  0.436957   0.186900  1600  \n",
       "..        ...       ...       ...        ...   ...  \n",
       "726  0.254167  0.226642  0.652917   0.350133  2114  \n",
       "727  0.253333  0.255046  0.590000   0.155471  3095  \n",
       "728  0.253333  0.242400  0.752917   0.124383  1341  \n",
       "729  0.255833  0.231700  0.483333   0.350754  1796  \n",
       "730  0.215833  0.223487  0.577500   0.154846  2729  \n",
       "\n",
       "[731 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bikes = pd.read_csv('bike_rentals_cleaned.csv')\n",
    "df_bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b083680",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bikes = df_bikes.iloc[:,:-1]\n",
    "y_bikes = df_bikes.iloc[:,-1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_bikes, y_bikes, random_state= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d465a5",
   "metadata": {},
   "source": [
    "## 4.2.3 그레이디언트 부스팅 모델 배우기\n",
    "- 그레이디언트 부스팅 모델을 만드는 과정은 다음과 같다.\n",
    "\n",
    "-------\n",
    "1-1. 결정트리를 훈련한다. max_depth가 1인 결정 트리 스텀프를 사용하거나 Max_depth가 2나 3인 결정 트리를 사용할 수 있다.\n",
    "\n",
    "1-2. 기본학습기라 부르는 결정 트리는 높은 정확도를 위해 튜닝하지 않는다.\n",
    "\n",
    "1-3. 기본 학습기에 크게 의존하는 모델이 아니라 오차에서 학습하는 모델을 원하기 때문이다. \n",
    "\n",
    "#### 1-4. 앙상블의 첫번째 트리인 tree_1을 max_depth=2로 결정 트리를 초기화하고 훈련 세트에서 훈련한다.\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d0b471a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=2, random_state=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=2, random_state=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_1 = DecisionTreeRegressor(max_depth = 2, random_state=2)\n",
    "tree_1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6f7fa",
   "metadata": {},
   "source": [
    "---\n",
    "2. **테스트 세트가 아니라 훈련 세트에 대한 예측을 만든다.** 잔차를 계산하기 위해서 훈련 단계에서 예측과 타깃을 비교해야 하기때문이다. 모델의 테스트 단계는 모든 트리를 구성한 후 마지막에 온다. tree_1의 predict()메서드에 x_train을 입력하여 첫 번째 반복에 대한 훈련 세트 예측을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f1486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = tree_1.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd4ec00",
   "metadata": {},
   "source": [
    "- 잔차를 계산한다. 잔차는 예측과 타깃 사이의 차이이다.\n",
    "- X_train 예측인 y_train_pred를 타깃 y_train에서 빼어 잔차를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7727ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잔차는 다음 트리의 타깃이 되기 때문에 y2_train이라고 이름을 지었다.\n",
    "\n",
    "y2_train = y_train - y_train_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb88b8b8",
   "metadata": {},
   "source": [
    "4. 새로운 트리를 이 잔차에서 훈련한다. 잔차에서 트리를 훈련하는 것은 훈련 세트에서 훈련하는 것과 다르다. 주요한 차이는 예측값이다. 자전거 대여 데이터셋에서 잔차에 새로운 트리를 훈련할 때 점점 더 작은 값을 얻는다. 새로운 트리를 초기화하고 x_train, y2_train에서 훈련한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdcf3d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=2, random_state=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=2, random_state=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_2 = DecisionTreeRegressor(max_depth =2, random_state=2) # 초기화\n",
    "tree_2.fit(x_train, y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92b1050",
   "metadata": {},
   "source": [
    "5. 2~4단계를 반복한다. 이 과정이 계속되면서 잔차는 양수나 음수 방향으로 0에 가까워진다. 앙상블에 추가할 트리 개수만큼 반복이 계속된다. 세 번째 트리에서 이 과정을 반복해보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63afb681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=2, random_state=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=2, random_state=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_train_pred = tree_2.predict(x_train)\n",
    "y3_train = y2_train - y2_train_pred\n",
    "tree_3 = DecisionTreeRegressor(max_depth = 2, random_state=2)\n",
    "tree_3.fit(x_train, y3_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37061833",
   "metadata": {},
   "source": [
    "이 과정이 수십,수백,수천 개의 트리까지 계속될 수 있다. 일반적인 상황이라면 계속 진행될 것이다. 약한 학습기를 강력한 학습기로 만들려면 몇개 트리로는 부족하다. 여기서 목적은 그레이디언트 부스팅의 작동방식을 이해하는 것이기 때문에 일반적인 개념을 다룬 것에 만족하자.\n",
    "\n",
    "---\n",
    "6. 결과를 더하자. 다음처럼 최종 결과를 위해 테스트 세트에 대한 각 트리의 예측을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e377d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred = tree_1.predict(x_test)\n",
    "y2_pred = tree_2.predict(x_test)\n",
    "y3_pred = tree_3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "552a2a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y1_pred + y2_pred + y3_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6802c3f0",
   "metadata": {},
   "source": [
    "7. 마지막으로 다음처럼 평균 제곱근 오차를 계산하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6be8389f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911.0479538776444"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "MSE(y_test, y_pred)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e3ba3a",
   "metadata": {},
   "source": [
    "## 사이킷런 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2f61c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911.0479538776432"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사이킷런의 그레이디언트 부스틍 회귀 모델의 기본 손실 함수는 제곱 오차이고 \n",
    "# 분류 모델의 기본 손실 함수는 로지스틱 손실 함수이다.\n",
    "# 경사 하강법으로 두 함수를 미분하면 모두 y - y_pred꼴을 얻는다.\n",
    "\n",
    "# 타깃과 평균 사이 잔차1를 구한다.\n",
    "# 그 잔차로 훈련한다.\n",
    "res_1 = y_train - np.mean(y_train)\n",
    "tree_1.fit(x_train, res_1)\n",
    "\n",
    "# 잔차 2를 구한다.\n",
    "# 그 잔차2로 훈련한다.\n",
    "pred_1 = tree_1.predict(x_train)\n",
    "res_2 = y_train - pred_1\n",
    "tree_2.fit(x_train, res_2)\n",
    "\n",
    "# 잔차3을 구한다.\n",
    "# 그 잔차3으로 훈련한다.\n",
    "pred_2 = tree_2.predict(x_train)\n",
    "res_3 = y_train - (pred_1 + pred_2)\n",
    "tree_3.fit(x_train, res_3)\n",
    "\n",
    "# 앙상블에 추가된 세 개의 트리로 테스트 세트에 대한 예측을 만들어 모두 더하고 타깃과의 오차를 계산한다.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pred_all = tree_1.predict(x_test) + tree_2.predict(x_test) + tree_3.predict(x_test)\n",
    "mean_squared_error(y_test, pred_all, squared=False)\n",
    "\n",
    "# GradientBoostingClassifier의 경우 클래스별로 각 트리의 예측을 더한 후 시그모이드 함수를 적용한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae0e8e6",
   "metadata": {},
   "source": [
    "## 4.2.4 사이킷런으로 그레이디언트 부스팅 모델 만들기\n",
    "- 사이킷런의 GradientBoostingRegressor을 상요하면 이전 절과 동일한 결과를 얻을 수 있다.\n",
    "- GradientBoostingRegressor을 사용하면 그레이디언트 부스팅 알고리즘을 훨씬 빠르고 쉽게 구현가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7556cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 먼저 Sklearn.ensemble 모듈에서 GradientBoostingRegressor 클래스를 임포트\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff7f3ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GradientBoostingRegressor를 초기화할 때 중요한 매개변수가 몇 개 있다.\n",
    "# 이전 절과 동일한 결과를 얻기 위해 max_depth = 2, random_state=2로 지정하는 것이 중요하다.\n",
    "# 또한 세개의 트리만 사용하기 때문에 n_estimators=3으로 지정한다. 마지막으로 learning_rate = 3으로 설정한다.\n",
    "\n",
    "gbr = GradientBoostingRegressor(max_depth = 2, n_estimators = 3, random_state = 2, learning_rate = 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84a716a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911.0479538776439"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 이전 모델을 초기화했으므로 훈련데이터에서 훈련하고 테스트 데이터에서 모델을 평가해보자.\n",
    "gbr.fit(x_train, y_train)\n",
    "y_pred = gbr.predict(x_test)\n",
    "MSE(y_test, y_pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40e48da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857.1072323426944"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 30개의 트리로 그레이디언트 부스팅 회귀 모델을 만들고 평가해보겠다.\n",
    "gbr = GradientBoostingRegressor(max_depth = 2, n_estimators=30, random_state = 2, learning_rate=1.0)\n",
    "\n",
    "gbr.fit(x_train, y_train)\n",
    "y_pred = gbr.predict(x_test)\n",
    "MSE(y_test, y_pred)**0.5\n",
    "\n",
    "#rmse = np.sqrt(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72154b6b",
   "metadata": {},
   "source": [
    "MSE: MSE는 평균 제곱 오차(Mean Squared Error)로서, 실제값과 예측값 간의 오차를 **제곱하여** 평균을 구한 값입니다. 각 데이터 포인트에 대해 오차를 제곱한 후 모든 데이터 포인트에 대한 제곱 오차의 평균을 구합니다. MSE는 오차를 양수로 만들어주고, 특히 큰 오차의 영향을 강조합니다.\n",
    "\n",
    "**0.5: 이 부분은 MSE의 제곱근을 의미합니다. 제곱근을 취함으로써 오차의 원래 스케일로 돌아오게 됩니다. 즉, 예측 오차를 다시 원래의 단위로 변환하여 해석할 수 있게 됩니다. 예측 오차가 양의 값으로 제곱되었으므로, 제곱근을 취하면 오차가 항상 양수가 됩니다.\n",
    "\n",
    "Sqrt의 경우 제곱근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6abc77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936.3617413678853"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이번에는 300개를 늘려보겠다.\n",
    "gbr = GradientBoostingRegressor(max_depth = 2, n_estimators = 300, random_state=2, learning_rate=1.0)\n",
    "\n",
    "gbr.fit(x_train, y_train)\n",
    "y_pred = gbr.predict(x_test)\n",
    "MSE(y_test, y_pred)**0.5 # 실제값과 예측값의 차이 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aab48a",
   "metadata": {},
   "source": [
    "- 놀란다. 점수가 더 나빠졌다. 무엇을 잘못한걸까? \n",
    "- 놀라운 결과를 얻을 때마다 코드를 재차 확인해볼 필요가 있다.\n",
    "- 아직 자세히 설명하지 않았지만 learning_rate 매개변수를 바꿔보자. learning_rate = 1.0을 제거하고 사이킷런 기본값을 사용하면 어떻게 될까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c787e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653.7456840231495"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth = 2, n_estimators=300, random_state=2)\n",
    "gbr.fit(x_train, y_train)\n",
    "y_pred = gbr.predict(x_test)\n",
    "MSE(y_test, y_pred) **0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff6823",
   "metadata": {},
   "source": [
    "- 사이킷런의 learning_Rate 기본값을 상요해 점수를 936점에서 654로 낮추었다.\n",
    "- 다음 절에서 learning_rate 매개변수에 초점을 맞추면서 그레이디언트 부스팅의 다른 매개변수에 대해 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e156d339",
   "metadata": {},
   "source": [
    "# 4.3 그레이디언트 부스팅 매개변수 튜닝\n",
    "- 이절에서 가장 중요한 그레이디언트 부스팅의 매개변수인 learning_rate와 모델의 트리 개수 또는 반복 횟수인 n_estimators에 초점을 맞춰보겠다.\n",
    "\n",
    "- 또한 확률적 그레이디언트 부스팅을 만드는 subsample 매개변수도 알아보겠다. 그리고 RandomizedSearchCV를 사용해 XGBoost와 결과를 비교하겠다.\n",
    "\n",
    "## 4.3.1 leaning_rate\n",
    "- 이전 절에서 GradientBoostingRegressor의 learning_rate 매개변수 값을 1.0에서 사이킷런 기본값인 0.1로 바꾸어서 크게 성능을 높였다.\n",
    "\n",
    "- learning_Rate는 모델 구축에 너무 큰 영향을 끼지치 않도록 개별 트리의 기여를 줄인다.\n",
    "- 이를 축소라고도 부른다. 이 매개변수를 주의 깊게 조정하지 않고 기본 학습기의 오차를 기반으로 전체 앙상블을 만들면 모델에 처음 추가된 트리의 영향이 너무 크게 된다. learning_rate는 개별 트리의 영향을 제한한다. **일반적으로 트릭 개수인 n_estimators를 늘리면 learning_rate는 줄여야 한다.**\n",
    "\n",
    "- 최적의 learning_Rate값을 결정하는 것은 n_estimators에 따라 다르다. 먼저 n_estimators를 고정하고 \n",
    "- learning_rate의 효과를 확인해보겠다.\n",
    "- learning_rate를 0에서 1까지 바꾸어보겠다. learning_Rate이 1이면 트리 결과에 어떤 조정도 하지 않는다는 의미\n",
    "- 기본값 0.1은 트리의 영향을 10%로 줄인다는 뜻. (모델에 처음 추가된 트리의 영향이 큼)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe6d032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 테스트 범위 정의\n",
    "learning_rate_values = [0.001, 0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.5, 1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80560bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습률: 0.001 , 점수: 1633.0261400367253\n",
      "학습률: 0.01 , 점수: 831.5430182728547\n",
      "학습률: 0.05 , 점수: 685.0192988749716\n",
      "학습률: 0.1 , 점수: 653.7456840231495\n",
      "학습률: 0.15 , 점수: 687.666134269379\n",
      "학습률: 0.2 , 점수: 664.312804425697\n",
      "학습률: 0.3 , 점수: 689.4190385930236\n",
      "학습률: 0.5 , 점수: 693.8856905068778\n",
      "학습률: 1 , 점수: 936.3617413678853\n",
      "학습률: 0 , 점수: 1983.0258367489087\n"
     ]
    }
   ],
   "source": [
    "for value in learning_rate_values:\n",
    "    gbr = GradientBoostingRegressor(max_depth = 2, n_estimators=300, random_state=2, learning_rate = value)\n",
    "    \n",
    "    gbr.fit(x_train, y_train)\n",
    "    y_pred = gbr.predict(x_test)\n",
    "    rmse = MSE(y_test, y_pred)**0.5\n",
    "    print('학습률:', value, ', 점수:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a613ef",
   "metadata": {},
   "source": [
    "- 출력에서 볼 수 있듯이 기본 learning_rate 값 0.1이 300개의 트리에서 가장 좋은 성능을 낸다.\n",
    "- **정말 중요한점** learning_rate와 n_estimators 매개변수를 함께 튜닝해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdd1ff3",
   "metadata": {},
   "source": [
    "## 4.3.2 기본 학습기\n",
    "- 그레이디언트 부스팅 회귀 모델의 기본학습는 결정 트리이다.\n",
    "- 이 결정 트리를 미세 튜닝할 필요가 없지만 2장에서 소개한 것처럼 정확도를 높이기 위해 기본 학습기의 매개변수를 조정할 수 있다.\n",
    "- 예를들어 max_depth를 1,2,3,4로 바꾸면서 결과를 비교해볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9cf5432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대깊이: None 점수: 874.8692494690362\n",
      "최대깊이: 1 점수: 727.9758708484177\n",
      "최대깊이: 2 점수: 654.2140821630711\n",
      "최대깊이: 3 점수: 646.4043764510722\n",
      "최대깊이: 4 점수: 658.1704956239338\n"
     ]
    }
   ],
   "source": [
    "depths = [None, 1,2,3,4]\n",
    "for depth in depths:\n",
    "    gbr = GradientBoostingRegressor(max_depth = depth, n_estimators=200, random_state=2)\n",
    "    gbr.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = gbr.predict(x_test)\n",
    "    rmse = MSE(y_test, y_pred)**0.5\n",
    "    print('최대깊이:', depth, '점수:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efec621c",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor의 손실 그래프 그리기\n",
    "- 사이킷런의 GradientBoostingClassifier와 GradientBoostingRegressor는 모두 잔차를 타깃으로 결정트리를 훈련하기 때문에 약한 학습기로 DecisionTreeRegressor(splitter = 'best')를 사용한다. max_depth 매개변수의 기본값은 3이다.\n",
    "---\n",
    "- 앞서 언급한 것처럼 첫 번째 잔차를 계산하기 위한 초기 모델은 **init_속성에 저장되어 있다.** 회귀일 경우 타깃 평균을 계산하는 DummyRegressor() 객체이고 분류일 경우 다수 클래스를 예측하는 DummyClassifier() 객체이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d652f21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyRegressor</label><div class=\"sk-toggleable__content\"><pre>DummyRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyRegressor()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.init_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42b024bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 앙상블에 추가된 트리는 estimators_ 속성에 저장되어 있다. \n",
    "# 이 배열의 길이를 확인하면 앙상블에 추가된 트리의 개수를 알 수 있다.\n",
    "len(gbr.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8deedc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그레이디언트 부스팅 모델에 트리를 추가하면서 줄어드는 손실 함수 값은 train_score_속성에 저장되어 있다.\n",
    "# 이 속성을 사용해 트리가 추가되면서 줄어드는 손실 값을 그래프로 출력해보겠다.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(range(1, 201), gbr.train_score_)  # range(1, 301)을 range(1, 201)로 수정\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('train_score_')\n",
    "plt.title('Train Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca8f503",
   "metadata": {},
   "source": [
    "- 초기에 손실이 크게 줄어들지만 트리 개수가 30개 정도를 넘어가면서 완만해지는 것을 볼 수 있다.\n",
    "- 사이킷런의 그레이디언트 부스팅 클래스는 일정한 수준 이상 향상되지 않으면 훈련을 종료할 수 있는 조기 종료 기법을 제공한다.\n",
    "- validation_fraction(기본값 0.1)만큼 훈련 세트에서 검증 데이터를 덜어낸 다음 n_iter_no_change 반복 횟수 동안 검증 점수가 tol(기본값 1e~4)만큼 향상되지 않으면 훈련을 종료한다. n_iter_no_change의 기본값은 None으로 조기 조욜를 수행하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e9b9e1",
   "metadata": {},
   "source": [
    "## 4.3.3 subsample\n",
    "- subsample 매개변수는 기본 학습기에 사용될 샘플의 비율을 지정한다.\n",
    "- subsample을 1.0보다 작게 설정하면 트리를 훈련할 때 샘플의 일부만 사용하게 된다.\n",
    "- 예를들어 subsample = 0.8은 80%의 훈련 세트만 사용하여 각 트리를 훈련한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e034886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsample: 1 , 점수: 646.4045923317708\n",
      "subsample: 0.9 , 점수: 620.1819001443569\n",
      "subsample: 0.8 , 점수: 617.2355650565677\n",
      "subsample: 0.7 , 점수: 608.5878109774266\n",
      "subsample: 0.6 , 점수: 636.998132650159\n",
      "subsample: 0.5 , 점수: 626.9974073227554\n"
     ]
    }
   ],
   "source": [
    "samples = [1, 0.9, 0.8, 0.7, 0.6, 0.5]\n",
    "for sample in samples:\n",
    "    gbr = GradientBoostingRegressor(max_depth = 3, n_estimators = 300, subsample = sample, random_state = 2)\n",
    "    \n",
    "    gbr.fit(x_train, y_train)\n",
    "    y_pred = gbr.predict(x_test)\n",
    "    rmse = MSE(y_test, y_pred)**0.5\n",
    "    print('subsample:', sample, ', 점수:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b72be1",
   "metadata": {},
   "source": [
    "## 4.3.4 RandomizedSearchCV\n",
    "- 잘 동작하는 모델을 얻었지만 아직 2장에서 소개한 그리드 서치를 수행하지 않았다. 앞선 모델을 참고했을 때\n",
    "- max_depth=3, subsample = 0.7, n_estimators = 300, learning_rate = 0.1 근처가 그리드 서치로 탐색하기 좋은 출발점이다.\n",
    "- n_estimators는 높이고 learning_rate는 낮추는 것이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31271aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 탐색할 매개변수 리스트를 지정한다.\n",
    "\n",
    "params = {'subsample': [0.65, 0.7, 0.75],\n",
    "           'n_estimators': [300,500,1000],\n",
    "           'learning_rate': [0.05, 0.075, 0.1]\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab72da1d",
   "metadata": {},
   "source": [
    "- n_estimators는 300에서 시작해서 증가시키고, learning_rate는 0.1에서 시작해서 줄인다. 분산을 줄이기 위해 max_depth = 3으로 유지하겠다.\n",
    "- 가능한 하이퍼파라미터 조합이 27개이므로 RandomizedSearchCV를 사용해 이 조합에서 10번을 시도해 좋은 모델을 찾아보겠다.\n",
    "\n",
    "> **GridSearchCV**로도 27번의 조합을 탐색할 수 있지만 어느 순간 조합이 많아지면 **RandomizedSearchCV**가 필요하다. 여기서는 속도를 높이고 연습하기 위해서 **RandomizedSearchCV**를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8abb94ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. RandomizedSearchCV를 임포트하고 그레이디언트 부스팅 모델을 초기화한다.\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "gbr = GradientBoostingRegressor(max_depth = 3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62875626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그 다음 gbr과 Parmas, 반복 횟수, 측정 지표, 폴드 개수를 입력으로 사용해 RandomizedSearchCV 객체를 초기화한다.\n",
    "# 속도를 높이기 위해 n_jobs = -1로 지정하고 동일한 결과를 얻기 위해 random_State = 2로 지정한다.\n",
    "\n",
    "rand_reg = RandomizedSearchCV(gbr, params, n_iter = 10, scoring = 'neg_mean_squared_error', cv = 5, n_jobs = -1, random_state= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c68343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 모델을 훈련세트에 훈련하고 최상의 매개변수와 점수를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6785ec47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'subsample': 0.65, 'n_estimators': 300, 'learning_rate': 0.05}\n",
      "훈련 점수: 636.799\n",
      "테스트 세트 점수: 625.985\n"
     ]
    }
   ],
   "source": [
    "rand_reg.fit(x_train, y_train)\n",
    "best_model = rand_reg.best_estimator_\n",
    "best_params = rand_reg.best_params_\n",
    "print(\"최상의 매개변수:\", best_params)\n",
    "best_score = np.sqrt(-rand_reg.best_score_)\n",
    "print(\"훈련 점수: {:.3f}\".format(best_score))\n",
    "y_pred = best_model.predict(x_test)\n",
    "rmse_test = MSE(y_test, y_pred)**0.5\n",
    "print('테스트 세트 점수: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7adeb",
   "metadata": {},
   "source": [
    "- 이 매개변수에서 한 개씩 또는 여러 개의 매개변수를 바꿔서 실험해볼 수 있다. n_estimators = 300이 최상의 모델이지만 learning rate를 조정하고 n_estimators를 증가시켜 더 좋은 결과를 얻을 수 있다. subsample도 실험가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63b17db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597.7852637855387"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. 몇 번의 실험을 반복한 후에 다음 모델을 얻었다.\n",
    "# 더 좋아질 수도 있다. 도전해보자.\n",
    "gbr = GradientBoostingRegressor(max_depth = 3, n_estimators = 1600, subsample = 0.75, learning_rate =0.02,\n",
    "                               random_state = 2)\n",
    "gbr.fit(x_train, y_train)\n",
    "y_pred = gbr.predict(x_test)\n",
    "MSE(y_test, y_pred)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f9d73",
   "metadata": {},
   "source": [
    "## 4.3.5 XGBoost\n",
    "- XGBoost는 일반적인 구조는 동일한 그레이디언트 부스팅의 고급 버전이다.\n",
    "- 즉 잔차로부터 훈련한 트리를 추가하여 약한 학습기를 강력한 학습기로 바꾼다.\n",
    "- 이전 절에서 소개한 매개변수와 다른 것은 learning_rate으로 XGBoost에서는 eta이다.\n",
    "- 동일한 매개변수로 XGBoost 회귀 모델을 만들어보고 결과를 비교해보겠다.\n",
    "- 다음처럼 XGBoost 패키지에서 XGBRegressor를 임포트하고, 모델을 초기화하고 훈련한 다음 점수를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6adfe4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584.3395337495713"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xg_reg = XGBRegressor(max_depth = 3, n_estimators = 1600, eta = 0.02, subsample = 0.75, random_state =2)\n",
    "xg_reg.fit(x_train, y_train)\n",
    "y_pred = xg_reg.predict(x_test)\n",
    "MSE(y_test, y_pred)**0.5\n",
    "\n",
    "# 성능도 좋고 빠르네.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203d6d88",
   "metadata": {},
   "source": [
    "# 4.4 빅 데이터 다루기 - 그레이디언트 부스팅 vs XGBoost\n",
    "- 현실 세계의 데이터셋은 거대하며 소조 개의 데이터 포인트로 이루어질 수 있다.\n",
    "- 컴퓨터 한 대의 자원은 제약되어 있기 때문에 한 대의 컴퓨터로만 작업하는 것은 단점이 될 수 있다.\n",
    "- 빅 데이터를 다룰 때 종종 병렬 컴퓨팅을 활용하기 때문에 클라우드를 사용한다.\n",
    "- 대용량 데이터셋은 계산의 한계를 넘어설 때가 있다.\n",
    "- 이 책에서 지금까지 사용한 데이터셋은 수만 개의 행과 수 백개 이하의 열로 이루어져 있다.\n",
    "- 실행 시간이 오래 걸리지 않아 (대부분) 오류가 발생하지 않는다.\n",
    "\n",
    "---\n",
    "- 이 절에서는 외계 행서 데이터셋을 살펴보겠다.\n",
    "- 이 데이터셋은 5,087개의 행과 3,189개의 열로 이루어져있다.\n",
    "- 별의 생명 주기 동안에 빛의 밝기를 기록한 것이다.\n",
    "- 행과 열의 개수를 곱하면 1500만 포이트가 된다.\n",
    "- 100개의 트리를 사용한다면 모델을 구축하기 위해 15억개 데이터 포인터를 처리해야 한다.\n",
    "- 이절의 코드를 실행하는데 2013년형 맥북 에어로 약 5분이 걸렸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d5728e",
   "metadata": {},
   "source": [
    "## 4.4.1 외계 행성 데이터셋 소개\n",
    "- 외계 행성 데이터셋은 2017년 캐글에 소개된 데이터셋이다.\n",
    "- 이 데이터셋에는 별의 밝기에 대한 정보가 포함되어 있다.\n",
    "- 각 행은 하나의 별에 대한 정보를 나타내며 각 열은 시간에 따라 밝기의 변화를 저장하고 있다.\n",
    "- 밝기 외에도 LABEL 열에는 별이 외계 행성을 가지고 있으며 2 아니면 1로 레이블되어 있다.\n",
    "- 이 데이터셋은 수천 개의 별의 밝기를 담고 있따. 별의 밝기는 종종 광속이라고도 부르며 감지된 별의 밝기이다.\n",
    "\n",
    "> 감지된 밝기는 실제 밝기와 다르다. 예를 들어 멀리 떨어진 매우 밝은 별의 광속은 작을 수 있다.(흐리게 보인다.)\n",
    "이에 반해 매우 가까운 거리에 있는 중간 밝기의 별이 높은 광속을 가질수 있다.(밝게 보인다.)\n",
    "\n",
    "- 별의 밝기가 주기적으로 달라질 때 외계 행성이 이 별을 공전하고 읽을 가능성이 있다.\n",
    "- 외계 행성이 별의 앞을 지나갈 때 빛의 일부분을 가리고 이로 인해 별의 밝기가 약간 감소된다고 가정한 것이다.\n",
    "\n",
    "> 외계 행성을 찾는 일은 드뭅니다. 별이 외계 행성을 가지고 있는지 아닌지 나타내는 LABEL 열을 보면 외계행성이 있는 경우가 많지 않다. 따라서 이 데이터셋은 불균형하다. 7장에서 이 데이터셋을 더 자세하게 살펴보면서 불균형한 데이터셋에 대해 다루겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed4429a",
   "metadata": {},
   "source": [
    "## 4.42 외계 행성 데이터셋 전처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c00fcafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n",
       "0      2    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
       "1      2   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
       "2      2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
       "3      2   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
       "4      2 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
       "\n",
       "    FLUX.8  FLUX.9  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0   -96.27  -79.89  ...     -78.07    -102.15    -102.15      25.13   \n",
       "1   -85.33  -83.97  ...      -3.28     -32.21     -32.21     -24.89   \n",
       "2   486.39  436.56  ...     -71.69      13.31      13.31     -29.89   \n",
       "3   311.31  312.42  ...       5.71      -3.73      -3.73      30.05   \n",
       "4 -1022.71 -989.57  ...    -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('exoplanets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51722c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5087 entries, 0 to 5086\n",
      "Columns: 3198 entries, LABEL to FLUX.3197\n",
      "dtypes: float64(3197), int64(1)\n",
      "memory usage: 124.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dca4e09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d871f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 X와 y로 나눕니다.\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0] \n",
    "\n",
    "# 훈련 세트와 테스트 세트로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98311ef0",
   "metadata": {},
   "source": [
    "# 4.43 그레이디언트 부스팅 분류 모델 만들기\n",
    "- 그레이디언트 부스팅 분류 모델은 그레이디언트 회귀 모델과 같은 방식으로 동작한다. 측정 지표가 주요한 차이점이다.\n",
    "- GradientBoostingClassifier와 XGBClassifier, accuracy_score를 임포트하여 두 모델을 비교 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e17c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# XGBRegressor를 임포트합니다.\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# accuracy_score를 임포트합니다.\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e33c6",
   "metadata": {},
   "source": [
    "# 4.4.4 시간 측정\n",
    "- 파이썬은 시간을 측정하는 데 사용할 수 있는 time패키지를 제공한다.\n",
    "- 모델을 훈련하고 평가하기 전후의 시간을 기록하는 것이 일반적인 방법이다.\n",
    "- 두 시간의 차이가 모델을 훈련하고 평가하는 데 걸리는 시간이다.\n",
    "\n",
    "다음처럼 time 패키지를 임포트한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c357597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5087 entries, 0 to 5086\n",
      "Columns: 3198 entries, LABEL to FLUX.3197\n",
      "dtypes: float64(3197), int64(1)\n",
      "memory usage: 124.1 MB\n",
      "\n",
      "실행 시간: 0.010210990905761719 초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "df.info()\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "\n",
    "print('\\n실행 시간: ' + str(elapsed) + ' 초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e86d33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780 µs ± 6.66 µs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 100 -r 3 sum(np.square(range(10000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27742144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.03 ms ± 20 µs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 3 \n",
    "summing = 0\n",
    "for i in range(10000):\n",
    "    summing += i**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4267ad13",
   "metadata": {},
   "source": [
    "## 4.4.5 속도 비교\n",
    "- 이제 외계 행성 데이터셋을 사용해 GradientBoostingClassifier와 XGBoostClassifier의 속도를 비교\n",
    "- 모델의 크기를 제한하기 위해 max_depth =2와 n_estimators = 100으로 설정하겠다.\n",
    "- GradientBoostingClassifier부터 시작해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e10c14a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점수: 0.9874213836477987\n",
      "실행 시간: 181.03421807289124 초\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "gbr = GradientBoostingClassifier(n_estimators=100, \n",
    "                                 max_depth=2, random_state=2)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict(X_test)\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('점수: ' + str(score))\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "\n",
    "print('실행 시간: ' + str(elapsed) + ' 초')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4adcf416",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m xg_reg \u001b[38;5;241m=\u001b[39m XGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 훈련 세트에서 xg_reg를 훈련합니다.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mxg_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 테스트 세트에 대한 예측을 만듭니다.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xg_reg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1440\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1435\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1437\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1438\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m   1439\u001b[0m ):\n\u001b[0;32m-> 1440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1441\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1442\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1443\u001b[0m     )\n\u001b[1;32m   1445\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# XGBRegressor를 초기화합니다.\n",
    "xg_reg = XGBClassifier(n_estimators=100, max_depth=2)\n",
    "\n",
    "# 훈련 세트에서 xg_reg를 훈련합니다.\n",
    "xg_reg.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 세트에 대한 예측을 만듭니다.\n",
    "y_pred = xg_reg.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "\n",
    "print('점수: ' + str(score))\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "\n",
    "print('실행 시간: ' + str(elapsed) + ' 초')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed6e364",
   "metadata": {},
   "source": [
    "## 마치며 \n",
    "\n",
    "이 장에서 배깅과 부스팅의 차이에 대해 배웠다. 직접 그레이디언트 부스팅 회귀 모델을 만들면서 작동 방식을 배웠다.\n",
    "learning_rate, n_estimators, max_depth와 확륙적 그레이디언트 부스팅을 만드는 usbsample 매개변수 등 다양한 그레이디언트 부스팅 매개변수로 모델을 만들었다. 마지막으로 외계 행성을 가진 별인지 예측하기 위한 대용량 데이터셋으로 GraidientBoostingClassifier와 XGBoostClassifier를 비교해보았다. \n",
    "XGBoostClassifier가 2배에서 10배까지 빠르고 더 정확하다.\n",
    "\n",
    "이런 기술을 배움으로써 그레이디언트 부스팅 같이 비슷한 머신러닝 알고리즘 대신 XGBoost를 적용해야 할 시기를 이해할 수 있다. 이제 n_esxtimators와 learning_rate와 같은 핵심 매개변수를 적절히 활용하여 강력한 XGBoost 모델과 그레이디언트 부스팅 모델을 만들 수 있다. 또한 직관에 의존하는 대신 계산 시간을 측정할 수 있는 방법을 배웟다.\n",
    "\n",
    "지금까지는 XGBoost의 거시적 측면에서 머신러닝과 데이터 분섹에 대해 소개하는 것이 목적이었다.\n",
    "앙상블 모델, 부스팅, 그레이디언트 부스팅, 빅데이터로부터 xGBoost의 필요성이 어떻게 탄생했는지 보여주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7227fdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a22bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f166fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ceeec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab3db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d3c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f33d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c6fd45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
